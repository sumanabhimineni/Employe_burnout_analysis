import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score
import pickle as pickle
import os
# import necesaary libs


data=pd.read_excel("/content/employee_burnout_analysis-AI.xlsx")
# upload dataset


data.head()
# displays the top 5 entries of the dataset(default)


data.tail()
# last 5 entries (default)


data.describe()
# statistical data


data.columns.tolist()
# converting column values to a list (easy to access)

data.nunique()
# number of unique values per column

data.info()
# info regarding dataset

data.isnull().sum()
# find null values

data.isnull().sum().values.sum()

data.corr(numeric_only=True)['Burn Rate'][:-1]
# variables are correlated
# burn rate column affecting the follwing named columns
# -1 to remove correlation of burnout rate and burnout rate


sns.pairplot(data)
plt.show()
# plotting graphs
# shows the distribution of data

data=data.dropna()
data.shape


data.dtypes

data=data.drop('Employee ID',axis=1)

print(f"Min Date: {data['Date of Joining'].min()}")
print(f"Max Date: {data['Date of Joining'].max()}")
data_month=data.copy()

data_month['Date of Joining']=data_month['Date of Joining'].astype("datetime64[ns]")
data_month['Date of Joining'].groupby(data_month['Date of Joining'].dt.month).count().plot(kind='bar', xlabel='Month', ylabel='Hired employees')
# find employee seniority
# correlation btw date of joining and burn rate (target varible)

data_2008=pd.to_datetime(["2008-01-01"]*len(data))
data["Days"]=data['Date of Joining'].astype('datetime64[ns]').sub(data_2008).dt.days
data.Days

numeric_data=data.select_dtypes(include=["number"])
correlation=numeric_data.corr()['Burn Rate']
print(correlation)
# correlation between seniority and burn rate

data.corr(numeric_only=True)['Burn Rate'][:]

data=data.drop(['Date of Joining', 'Days'], axis=1)

cat_columns=data.select_dtypes(['object']).columns
fig, ax=plt.subplots(nrows=1, ncols=len(cat_columns), sharey=True, figsize=(10,5))
for i,c in enumerate(cat_columns):
  sns.countplot(x=c, data=data, ax=ax[i])
plt.show()


if all(col in data.columns for col in ['Company Type', 'WFH Setup Available','Gender']):
  data=pd.get_dummies(data, columns=['Company Type', 'WFH Setup Available','Gender'], drop_first=True)
  data.head()
  encoded_columns=data.columns.tolist()
else:
  print("error: one or more columns are not present in dataset")
  print(data.columns)


y=data['Burn Rate']
X=data.drop('Burn Rate', axis=1)

scaler=StandardScaler()
scaler.fit(X_train)
X_train=pd.DataFrame(scaler.transform(X_train), columns=X_train.columns, index=X_train.index)
X_test=pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)

import os
import pickle
scaler_filename='../models/scaler.pkl'
os.makedirs(os.path.dirname(scaler_filename), exist_ok=True)
with open(scaler_filename, 'wb') as scaler_filename:
  pickle.dump(scaler, scaler_filename)

X_train

y_train

import os
import pickle

path='../data/processed/'
os.makedirs(path, exist_ok=True)
X_train.to_csv(path+'X_train_processed.csv', index=False)
X_test.to_csv(path+'X_test_processed.csv', index=False)

linear_regression_model=LinearRegression()
linear_regression_model.fit(X_train, y_train)

print("Linear Regression Model Performance Metrics:\n")
y_pred=linear_regression_model.predict(X_test)
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("Root Mean Squared Error: ",mean_squared_error(y_test, y_pred, squared=False))
print("Mean Absolute Error:", mean_absolute_error(y_test, y_pred))
print("R2 Score:", r2_score(y_test, y_pred))